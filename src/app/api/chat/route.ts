import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'
import { createServerClient as createClient } from '../../../../lib/supabase/server'
import { logTokenUsage, getUserTokenUsage } from '../../../../lib/services/tokenService'
import { calculateCost } from '../../../../lib/config/aiModels'

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞ –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç—Å—è –≤–Ω—É—Ç—Ä—å –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ POST, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–∞–¥–µ–Ω–∏—è —Å–±–æ—Ä–∫–∏ –±–µ–∑ –∫–ª—é—á–∞

const ARCANUM_BRAIN_PROMPT = `–¢—ã ‚Äî Chief Orchestrator AI –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã Arcanum...` // [existing prompt content]

// –ü–æ–ª—É—á–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏
function getMaxTokensForModel(modelId: string): number {
  const modelLimits: Record<string, number> = {
    'gpt-4o-mini': 4000,
    'gpt-4o': 4000, 
    'gpt-4-turbo': 4000,
    'gpt-4': 2000,
    'o1-preview': 8000,
    'o1-mini': 4000,
    'o3': 8000
  }
  return modelLimits[modelId] || 1000
}

// –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∫–æ–º–∞–Ω–¥—ã
function detectCommandType(message: string): string {
  const lowerMessage = message.toLowerCase()
  
  if (lowerMessage.includes('–¥–æ–±–∞–≤—å –∫–Ω–æ–ø–∫—É') || lowerMessage.includes('—Å–æ–∑–¥–∞–π –∫–Ω–æ–ø–∫—É')) {
    return 'create_button'
  }
  
  if (lowerMessage.includes('—Å–æ–∑–¥–∞–π –∑–∞–¥–∞—á—É') || lowerMessage.includes('–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞')) {
    return 'create_task'
  }
  
  if (lowerMessage.includes('–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π') && lowerMessage.includes('—Å—Ñ–µ—Ä')) {
    return 'analyze_spheres'
  }
  
  if (lowerMessage.includes('—Ä–µ–∂–∏–º —Ñ–æ–∫—É—Å–∞') || lowerMessage.includes('—Ñ–æ–∫—É—Å –Ω–∞')) {
    return 'focus_mode'
  }
  
  if (lowerMessage.includes('—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π') && (lowerMessage.includes('–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ') || lowerMessage.includes('–∞—Ä—Ç'))) {
    return 'generate_image'
  }
  
  if (lowerMessage.includes('–ø—Ä–æ–≥—Ä–µ—Å—Å') || lowerMessage.includes('—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞')) {
    return 'show_progress'
  }
  
  return 'general_chat'
}

// –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ Supabase
async function getUserContext(userId: string): Promise<string> {
  try {
    // –ó–¥–µ—Å—å –±–æ–ª—å—à–µ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º anonymous
    const supabase = createClient()
    
    // –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    const { data: userStats } = await supabase
      .from('user_stats')
      .select('level, current_xp, next_level_xp, energy')
      .eq('user_id', userId)
      .single()
    
    // –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ —Å—Ñ–µ—Ä—ã
    const { data: spheres } = await supabase
      .from('life_spheres')
      .select('sphere_name, health_percentage')
      .eq('user_id', userId)
      .eq('is_active', true)
      
    const contextData = userStats || {
      level: 1,
      current_xp: 0,
      next_level_xp: 100,
      energy: 100
    }
    
    const activeSpheres = (spheres && spheres.length > 0)
      ? spheres.map((s: { sphere_name: string; health_percentage: number }) => `${s.sphere_name} (${s.health_percentage}%)`).join(', ')
      : '–ó–¥–æ—Ä–æ–≤—å–µ (50%), –ö–∞—Ä—å–µ—Ä–∞ (50%), –§–∏–Ω–∞–Ω—Å—ã (50%)'
    
    const userContext = `
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ID: ${userId}
    –£—Ä–æ–≤–µ–Ω—å: ${contextData.level} (${contextData.current_xp?.toLocaleString()} / ${contextData.next_level_xp?.toLocaleString()} XP)
    –≠–Ω–µ—Ä–≥–∏—è: ${contextData.energy}%
    –ê–∫—Ç–∏–≤–Ω—ã–µ —Å—Ñ–µ—Ä—ã: ${activeSpheres}
    `
    
    return userContext.trim()
  } catch (error) {
    console.error('Error getting user context:', error)
    return ''
  }
}

export async function POST(request: NextRequest) {
  try {
    const { message, userId, modelId = 'gpt-4o-mini' } = await request.json()

    if (!message) {
      return NextResponse.json({ error: 'Message is required' }, { status: 400 })
    }

    // –¢—Ä–µ–±—É–µ–º –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é (–Ω–∏–∫–∞–∫–∏—Ö anonymous)
    if (!userId || userId === 'anonymous') {
      return NextResponse.json({
        error: 'AUTH_REQUIRED',
        message: '–¢—Ä–µ–±—É–µ—Ç—Å—è –≤—Ö–æ–¥ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —á–∞—Ç–∞',
        login_url: '/auth/login'
      }, { status: 401 })
    }

    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json({ error: 'OpenAI API key not configured' }, { status: 500 })
    }

    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

    console.log('Arcanum Brain processing message:', message, 'for user:', userId)

    const userContext = await getUserContext(userId)

    const commandType = detectCommandType(message)
    
    let systemPrompt = ARCANUM_BRAIN_PROMPT
    if (userContext) {
      systemPrompt += `\n\n–ö–û–ù–¢–ï–ö–°–¢ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:\n${userContext}`
    }

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–∫–µ–Ω-–ª–∏–º–∏—Ç—ã –ø–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º OpenAI API (–º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏—è)
    try {
      const userTokensUsed = await getUserTokenUsage(userId)
      const isPremium = false // TODO: –ø–æ–ª—É—á–∞—Ç—å –∏–∑ user_stats –∏–ª–∏ auth metadata
      const tokenLimit = isPremium ? 10000 : 1000
      
      if (userTokensUsed > tokenLimit) {
        console.log(`üö´ Token limit exceeded for user ${userId}: ${userTokensUsed}/${tokenLimit}`)
        return NextResponse.json({
          error: 'TOKEN_LIMIT',
          tokens_used: userTokensUsed,
          limit: tokenLimit,
          paywall: {
            type: 'token_limit',
            cost: 2.00,
            message: '–†–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å 2000 —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ $2?'
          }
        }, { status: 402 })
      }
    } catch (error) {
      console.error('Error checking token limits:', error)
    }

    const response = await openai.chat.completions.create({
      model: modelId,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: message }
      ],
      max_tokens: getMaxTokensForModel(modelId),
      temperature: 0.7,
    })

    const aiResponse = response.choices[0]?.message?.content || '–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∞—à –∑–∞–ø—Ä–æ—Å.'

    if (response.usage) {
      try {
        await logTokenUsage({
          user_id: userId,
          model_id: modelId,
          prompt_tokens: response.usage.prompt_tokens || 0,
          completion_tokens: response.usage.completion_tokens || 0,
          total_tokens: response.usage.total_tokens || 0,
          cost: calculateCost(modelId, response.usage.prompt_tokens || 0, response.usage.completion_tokens || 0)
        })
        console.log(`üí∞ Logged ${response.usage.total_tokens} tokens for user ${userId}`)
      } catch (error) {
        console.error('Failed to log token usage:', error)
      }
    }

    return NextResponse.json({ 
      response: aiResponse,
      commandType,
      modelUsed: modelId,
      tokensUsed: response.usage?.total_tokens || 0
    })

  } catch (error) {
    console.error('Error in Arcanum Brain API:', error)
    const errorMessage = error instanceof Error ? error.message : 'Unknown error'
    
    return NextResponse.json({
      response: `–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: ${errorMessage}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.`,
      type: 'system'
    }, { status: 500 })
  }
}

// GET –º–µ—Ç–æ–¥ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
export async function GET() {
  return NextResponse.json({ 
    message: 'Arcanum Brain Chat API',
    status: 'active',
    version: '1.0.0',
    hasApiKey: !!process.env.OPENAI_API_KEY,
    supportedModels: [
      'gpt-4o-mini', 'gpt-4o', 'gpt-4-turbo', 'gpt-4', 
      'o1-preview', 'o1-mini', 'o3'
    ],
    agents: [
      'Chief Orchestrator AI',
      'Button Programming Agent', 
      'Task Assessor Agent',
      'Resonating Task Agent',
      'Global Design Agent',
      'Mascot Generator Agent'
    ]
  })
} 